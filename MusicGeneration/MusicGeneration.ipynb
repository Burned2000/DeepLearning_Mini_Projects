{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(file):\n",
    "    \n",
    "    print(\"LOADING MUSIC FILE : \",file)\n",
    "    \n",
    "    notes = []\n",
    "    notes_to_parsed = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "    \n",
    "    #Grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "    \n",
    "    #Looping over all the instruments\n",
    "    if s2:\n",
    "        for part in s2.parts:\n",
    "\n",
    "            #Select elements of Piano\n",
    "\n",
    "            if 'Piano' in str(part):\n",
    "                notes_to_parse = part.recurse()\n",
    "\n",
    "\n",
    "                #Finding whether a particular element is a note or a chord\n",
    "\n",
    "                for element in notes_to_parse:\n",
    "\n",
    "                    #Note\n",
    "                    if isinstance(element, note.Note):\n",
    "                        notes.append(str(element.pitch))\n",
    "\n",
    "                    elif isinstance(element, chord.Chord):\n",
    "                        notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    else:\n",
    "        pass\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/A-Whole-New-World-(Theme-From-'Aladdin').mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Backstreet Boys - I Want It That Way.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Coldplay - Viva La Vida.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/darude-sandstorm.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Linkin Park - Numb (Tim Dawes Remix).mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Michael Jackson - Beat It.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Michael Jackson - Billie Jean.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/My-Heart-Will-Go-On-(From-'Titanic').mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Naruto - Naruto Main Theme-Short Version.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Naruto Shippuden - Naruto Shpippuuden Opening 9 (1).mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Naruto Shippuden - Naruto Shpippuuden Opening 9.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Never-Gonna-Give-You-Up-3.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Pirates Of The Caribbean - Davy Jones.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Pirates of the Caribbean - He's a Pirate (3) (1).mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Pokemon RedBlueYellow - Wild Pokemon Battle.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Queen - Bohemian Rhapsody.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schubert_D850_1.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schubert_D850_2.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schubert_D850_3.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schubert_D850_4.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schubert_D935_1.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schubert_D935_2.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schubert_D935_3.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schubert_D935_4.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schub_d760_1.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schub_d760_2.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schub_d760_3.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schub_d760_4.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schub_d960_1.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schub_d960_2.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schub_d960_3.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schub_d960_4.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schuim-1.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schuim-2.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schuim-3.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schuim-4.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schumm-1.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schumm-2.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schumm-3.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schumm-4.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schumm-5.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schumm-6.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schu_143_1.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schu_143_2.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/schu_143_3.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Simpsons.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Star-Wars-Theme-(From-'Star-Wars').mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Super Mario 64 - Medley.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Sword Art Online - Crossing Field (SAO OP).mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Tetris - Tetris Main Theme.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/The-Avengers.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Tokyo Ghoul - Unravel.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/Tony Iggy - Astronomia.mid\n",
      "LOADING MUSIC FILE :  D:/MusicGeneration/MusicData/toto-africa.mid\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "path = 'D:/MusicGeneration/MusicData/'\n",
    "\n",
    "\n",
    "#Read all the file names\n",
    "files = [i for i in os.listdir(path) if i.endswith('.mid')]\n",
    "\n",
    "#Reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    }
   ],
   "source": [
    "#Converting 2D array into an 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([231.,  33.,  31.,  11.,   8.,   9.,   6.,  11.,   6.,   4.]),\n",
       " array([1.0000e+00, 1.6170e+02, 3.2240e+02, 4.8310e+02, 6.4380e+02,\n",
       "        8.0450e+02, 9.6520e+02, 1.1259e+03, 1.2866e+03, 1.4473e+03,\n",
       "        1.6080e+03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Distribution of Notes\n",
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "#computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "As you can see here, no. of frequently occurring notes is around 170. \n",
    "Now, let us prepare new musical files which contain only the top frequent notes\n",
    "\"\"\"\n",
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preparing the input and output sequences as mentioned in the article:\n",
    "\"\"\"\n",
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing input sequences\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 32, 100)           17900     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 8, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 179)               46003     \n",
      "=================================================================\n",
      "Total params: 272,223\n",
      "Trainable params: 272,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 62784 samples, validate on 15696 samples\n",
      "Epoch 1/50\n",
      "62784/62784 [==============================] - 10s 161us/step - loss: 4.2019 - val_loss: 3.8984\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.89839, saving model to best_model.h5\n",
      "Epoch 2/50\n",
      "62784/62784 [==============================] - 6s 90us/step - loss: 3.6652 - val_loss: 3.6989\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.89839 to 3.69891, saving model to best_model.h5\n",
      "Epoch 3/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 3.4975 - val_loss: 3.5938\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.69891 to 3.59381, saving model to best_model.h5\n",
      "Epoch 4/50\n",
      "62784/62784 [==============================] - 6s 90us/step - loss: 3.3834 - val_loss: 3.5088\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.59381 to 3.50879, saving model to best_model.h5\n",
      "Epoch 5/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 3.2838 - val_loss: 3.4130\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.50879 to 3.41303, saving model to best_model.h5\n",
      "Epoch 6/50\n",
      "62784/62784 [==============================] - 6s 90us/step - loss: 3.2029 - val_loss: 3.3284\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.41303 to 3.32836, saving model to best_model.h5\n",
      "Epoch 7/50\n",
      "62784/62784 [==============================] - 6s 90us/step - loss: 3.1321 - val_loss: 3.2781\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.32836 to 3.27809, saving model to best_model.h5\n",
      "Epoch 8/50\n",
      "62784/62784 [==============================] - 6s 90us/step - loss: 3.0733 - val_loss: 3.2115\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.27809 to 3.21154, saving model to best_model.h5\n",
      "Epoch 9/50\n",
      "62784/62784 [==============================] - 6s 90us/step - loss: 3.0174 - val_loss: 3.1726\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.21154 to 3.17260, saving model to best_model.h5\n",
      "Epoch 10/50\n",
      "62784/62784 [==============================] - 6s 89us/step - loss: 2.9703 - val_loss: 3.1783\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.17260\n",
      "Epoch 11/50\n",
      "62784/62784 [==============================] - 6s 90us/step - loss: 2.9264 - val_loss: 3.1466\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.17260 to 3.14662, saving model to best_model.h5\n",
      "Epoch 12/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.8858 - val_loss: 3.1361\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.14662 to 3.13610, saving model to best_model.h5\n",
      "Epoch 13/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.8482 - val_loss: 3.0786\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.13610 to 3.07859, saving model to best_model.h5\n",
      "Epoch 14/50\n",
      "62784/62784 [==============================] - 6s 90us/step - loss: 2.8147 - val_loss: 3.0519\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.07859 to 3.05186, saving model to best_model.h5\n",
      "Epoch 15/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.7826 - val_loss: 3.0128\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.05186 to 3.01277, saving model to best_model.h5\n",
      "Epoch 16/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.7548 - val_loss: 2.9974\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.01277 to 2.99742, saving model to best_model.h5\n",
      "Epoch 17/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.7265 - val_loss: 2.9892\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.99742 to 2.98924, saving model to best_model.h5\n",
      "Epoch 18/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.7022 - val_loss: 2.9688\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.98924 to 2.96878, saving model to best_model.h5\n",
      "Epoch 19/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.6802 - val_loss: 2.9591\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.96878 to 2.95911, saving model to best_model.h5\n",
      "Epoch 20/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.6607 - val_loss: 2.9622\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.95911\n",
      "Epoch 21/50\n",
      "62784/62784 [==============================] - 6s 93us/step - loss: 2.6414 - val_loss: 2.9247\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.95911 to 2.92468, saving model to best_model.h5\n",
      "Epoch 22/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.6225 - val_loss: 2.9224\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.92468 to 2.92243, saving model to best_model.h5\n",
      "Epoch 23/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.6025 - val_loss: 2.9020\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.92243 to 2.90198, saving model to best_model.h5\n",
      "Epoch 24/50\n",
      "62784/62784 [==============================] - 6s 92us/step - loss: 2.5855 - val_loss: 2.8979\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.90198 to 2.89794, saving model to best_model.h5\n",
      "Epoch 25/50\n",
      "62784/62784 [==============================] - 6s 95us/step - loss: 2.5713 - val_loss: 2.8818\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.89794 to 2.88177, saving model to best_model.h5\n",
      "Epoch 26/50\n",
      "62784/62784 [==============================] - 6s 92us/step - loss: 2.5602 - val_loss: 2.8633\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.88177 to 2.86335, saving model to best_model.h5\n",
      "Epoch 27/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.5388 - val_loss: 2.8643\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.86335\n",
      "Epoch 28/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.5312 - val_loss: 2.8628\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.86335 to 2.86279, saving model to best_model.h5\n",
      "Epoch 29/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.5120 - val_loss: 2.8496\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.86279 to 2.84956, saving model to best_model.h5\n",
      "Epoch 30/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.5082 - val_loss: 2.8610\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.84956\n",
      "Epoch 31/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.4883 - val_loss: 2.8311\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.84956 to 2.83108, saving model to best_model.h5\n",
      "Epoch 32/50\n",
      "62784/62784 [==============================] - 6s 93us/step - loss: 2.4848 - val_loss: 2.8235\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.83108 to 2.82350, saving model to best_model.h5\n",
      "Epoch 33/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.4771 - val_loss: 2.8321\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.82350\n",
      "Epoch 34/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.4628 - val_loss: 2.8262\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.82350\n",
      "Epoch 35/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.4526 - val_loss: 2.8037\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.82350 to 2.80374, saving model to best_model.h5\n",
      "Epoch 36/50\n",
      "62784/62784 [==============================] - 6s 94us/step - loss: 2.4492 - val_loss: 2.8032\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.80374 to 2.80325, saving model to best_model.h5\n",
      "Epoch 37/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.4383 - val_loss: 2.7953\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.80325 to 2.79531, saving model to best_model.h5\n",
      "Epoch 38/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.4280 - val_loss: 2.7956\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.79531\n",
      "Epoch 39/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.4200 - val_loss: 2.8000\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.79531\n",
      "Epoch 40/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.4132 - val_loss: 2.7737\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.79531 to 2.77368, saving model to best_model.h5\n",
      "Epoch 41/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.4028 - val_loss: 2.7828\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.77368\n",
      "Epoch 42/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.3974 - val_loss: 2.7740\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.77368\n",
      "Epoch 43/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.3962 - val_loss: 2.7813\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.77368\n",
      "Epoch 44/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.3831 - val_loss: 2.7710\n",
      "\n",
      "Epoch 00044: val_loss improved from 2.77368 to 2.77095, saving model to best_model.h5\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62784/62784 [==============================] - 6s 90us/step - loss: 2.3727 - val_loss: 2.7742\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.77095\n",
      "Epoch 46/50\n",
      "62784/62784 [==============================] - 6s 90us/step - loss: 2.3758 - val_loss: 2.7685\n",
      "\n",
      "Epoch 00046: val_loss improved from 2.77095 to 2.76845, saving model to best_model.h5\n",
      "Epoch 47/50\n",
      "62784/62784 [==============================] - 6s 90us/step - loss: 2.3657 - val_loss: 2.7489\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.76845 to 2.74893, saving model to best_model.h5\n",
      "Epoch 48/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.3640 - val_loss: 2.7422\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.74893 to 2.74217, saving model to best_model.h5\n",
      "Epoch 49/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.3542 - val_loss: 2.7422\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.74217\n",
      "Epoch 50/50\n",
      "62784/62784 [==============================] - 6s 91us/step - loss: 2.3514 - val_loss: 2.7504\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.74217\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52, 92, 92, 92, 92, 92, 154, 28, 154, 154]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(10):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
